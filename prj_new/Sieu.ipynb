{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-NJ2QoENDES"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nedc4PEzMxZs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "os.chdir(\"/home/sieu/PycharmProjects/ML-Vincent-Ng/prj_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqb0XC5HOl5q"
   },
   "source": [
    "# Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MqbBwV2BkPtY"
   },
   "outputs": [],
   "source": [
    "column_name = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "df = pd.read_table('train.txt', sep=\"\\s+\", usecols=all, names = list(column_name['attr']))\n",
    "# Add validation set\n",
    "dfX_pred = pd.read_table('prelim.txt', sep=\"\\s+\", usecols=all, names = list(column_name['attr']))\n",
    "df = pd.concat((df,dfX_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust year\n",
    "df.eval('YEAR = YEAR - 2000', inplace=True)\n",
    "dfX_pred.eval('YEAR = YEAR - 2000', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(17000, 177)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build histogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.hist(figsize=(90, 90))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate class from attributes\n",
    "y = df[\"Class\"].to_numpy()\n",
    "X = df[df.columns[:-1]]\n",
    "attr_lst = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B1' 'B2' 'B3' 'C1' 'C2' 'C3' 'C4' 'C5' 'C6' 'C7' 'C8' 'C9' 'C10' 'C11'\n",
      " 'C12' 'C13' 'C14' 'C15' 'C16' 'C17' 'C18' 'C19' 'C20' 'C21' 'C22' 'C23'\n",
      " 'C24' 'C25' 'C26' 'C27' 'C28' 'C29' 'C30' 'C31' 'C32' 'C33' 'C34' 'C35'\n",
      " 'C36' 'C37' 'C38' 'C39' 'C40' 'C41' 'C42' 'C43' 'C44' 'C45' 'C46' 'C47'\n",
      " 'C48' 'C49' 'C50' 'C51' 'C52' 'C53' 'C54' 'C55' 'C56' 'C57' 'C58' 'C59'\n",
      " 'C60' 'C61' 'C62' 'C63' 'C64' 'C65' 'C66' 'C67' 'C68' 'C69' 'C70' 'C71'\n",
      " 'C72' 'C73' 'C74' 'C75' 'C76' 'C77' 'C78' 'C79' 'C80' 'C81' 'C82' 'C83'\n",
      " 'C84' 'C85' 'C86' 'C87' 'C88' 'C89' 'C90' 'C91' 'C92' 'C93' 'C94' 'C95'\n",
      " 'C96' 'C97' 'C98' 'C99' 'C100' 'C101' 'C102' 'C103' 'C104' 'C105' 'C106'\n",
      " 'C107' 'C108' 'C109' 'C110' 'C111' 'C112' 'C113' 'C114' 'C115' 'C116'\n",
      " 'C117' 'C118' 'C119' 'C120' 'C121' 'C122' 'C123' 'C124' 'C125' 'C126'\n",
      " 'C127' 'C128' 'C129' 'C130' 'C131' 'C132' 'C133' 'C134' 'C135' 'C136'\n",
      " 'C137' 'C138' 'C139' 'YEAR' 'C140' 'C141' 'C142' 'CT1' 'CT2' 'CT3' 'CT4'\n",
      " 'CT5' 'CT6' 'CT9' 'CT10' 'CT11' 'CT12' 'CT13' 'CT14' 'CT15' 'CT16' 'CT17'\n",
      " 'CT18' 'CT19' 'CT20' 'CT21' 'CT22' 'CT23' 'CT24' 'CT25' 'CT26' 'CH1'\n",
      " 'CH3']\n",
      "Number of features:  172\n",
      "(17000, 172)\n"
     ]
    }
   ],
   "source": [
    "# Remove all constant-valued features\n",
    "sel = VarianceThreshold()\n",
    "sel.feature_names_in_= attr_lst\n",
    "X=sel.fit_transform(X)\n",
    "attr_lst=sel.get_feature_names_out(attr_lst)\n",
    "print(attr_lst)\n",
    "print(\"Number of features: \", len(attr_lst))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select good features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_fet_to_sel = len(attr_lst)//3\n",
    "\n",
    "print(\"BEGIN: HistGrad classifier feature selection\")\n",
    "berNB = SequentialFeatureSelector(estimator=HistGradientBoostingClassifier(max_leaf_nodes=60,max_iter=3000,learning_rate=0.06,l2_regularization=0.15, max_depth=8, max_bins=24, early_stopping=True, random_state=0),n_features_to_select=n_fet_to_sel, direction=\"forward\").fit(X, y)\n",
    "berNB.feature_names_in_= attr_lst\n",
    "attr_lst = berNB.get_feature_names_out(attr_lst)\n",
    "print(attr_lst)\n",
    "print(\"Done HistGrad classifier feature selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection results\n",
    "with open(\"histgrad.pkl\", 'wb') as file:\n",
    "    pickle.dump(attr_lst, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['B1', 'B2', 'C1', 'C2', 'C3', 'C4', 'C6', 'C7', 'C8', 'C10', 'C11',\n       'C15', 'C23', 'C26', 'C28', 'C31', 'C41', 'C46', 'C56', 'C71',\n       'C76', 'C86', 'C101', 'C116', 'C131', 'C136', 'C137', 'C138',\n       'C139', 'YEAR', 'C140', 'C141', 'C142', 'CT1', 'CT2', 'CT3', 'CT4',\n       'CT5', 'CT6', 'CT9', 'CT10', 'CT11', 'CT12', 'CT13', 'CT14',\n       'CT15', 'CT16', 'CT17', 'CT18', 'CT19', 'CT20', 'CT21', 'CT22',\n       'CT23', 'CT24', 'CT25', 'CT26'], dtype='<U4')"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load good feature list\n",
    "with open(\"histgrad.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file).astype(str)\n",
    "print(attr_lst)\n",
    "print(len(attr_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# Load from clipboard (either load from file or load from clipboard)\n",
    "attr_lst = ['B1', 'B2', 'C1', 'C2', 'C3', 'C4', 'C6', 'C7', 'C8', 'C10', 'C11',\n",
    "       'C15', 'C23', 'C26', 'C28', 'C31', 'C41', 'C46', 'C56', 'C71',\n",
    "       'C76', 'C86', 'C101', 'C116', 'C131', 'C136', 'C137', 'C138',\n",
    "       'C139', 'YEAR', 'C140', 'C141', 'C142', 'CT1', 'CT2', 'CT3', 'CT4',\n",
    "       'CT5', 'CT6', 'CT9', 'CT10', 'CT11', 'CT12', 'CT13', 'CT14',\n",
    "       'CT15', 'CT16', 'CT17', 'CT18', 'CT19', 'CT20', 'CT21', 'CT22',\n",
    "       'CT23', 'CT24', 'CT25', 'CT26']\n",
    "attr_lst=np.array(attr_lst)\n",
    "print(len(attr_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_C_mask = and(C, not(CT or CH))\n",
    "all_C_mask = np.logical_and((np.core.defchararray.find(attr_lst,\"C\")!=-1), np.logical_not(np.logical_or((np.core.defchararray.find(attr_lst,\"CT\")!=-1),(np.core.defchararray.find(attr_lst,\"CH\")!=-1))))\n",
    "# non_C_mask = not(all_C_mask)\n",
    "non_C_mask = np.logical_not(all_C_mask)\n",
    "# final_mask = and(non_C_mask, not(CH_mask))\n",
    "final_mask = np.logical_and(non_C_mask, np.logical_not((np.core.defchararray.find(attr_lst,\"CH\")!=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=df[attr_lst].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = dfX_pred[attr_lst].to_numpy()\n",
    "y_pred = dfX_pred[\"Class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((20570, 57), (20570,))\n"
     ]
    }
   ],
   "source": [
    "damage = 1 #5\n",
    "threshold = (15,35) #(2,12)\n",
    "rng = np.random.default_rng(12345)\n",
    "kfold = sklearn.model_selection.StratifiedKFold(n_splits=100, shuffle=True)\n",
    "y_new = y\n",
    "i=0\n",
    "\n",
    "for train_index , test_index in kfold.split(X_new, y_new):\n",
    "    if i > threshold[1]:\n",
    "        i+=1\n",
    "        continue\n",
    "    if i < threshold[0]:\n",
    "        i+=1\n",
    "        continue\n",
    "    X_new_aug, y_new_aug = X_new[test_index], y_new[test_index]\n",
    "    aug_mask = rng.choice(a=[0,1], size=X_new_aug.shape, p=[1-(damage*i)/100, (damage*i)/100])\n",
    "    X_new_aug[aug_mask] = np.nan\n",
    "    X_new = np.concatenate((X_new, X_new_aug), axis=0)\n",
    "    y_new = np.concatenate((y_new, y_new_aug))\n",
    "    i+=1\n",
    "print((X_new.shape, y_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin CV\n",
      "0.7792902284880895\n",
      "0.7751579970831308\n",
      "0.7812348079727759\n",
      "0.7736995624696159\n",
      "0.7817209528439475\n",
      "CV mean score:  0.7782207097715119\n",
      "Train set score:  0.876421973748177\n"
     ]
    }
   ],
   "source": [
    "# Best model validation\n",
    "kfold = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n",
    "arr = []\n",
    "#clf = BernoulliNB()\n",
    "clf = HistGradientBoostingClassifier(max_leaf_nodes=60,max_iter=3000,learning_rate=0.06,l2_regularization=0.15, max_depth=8, max_bins=24, early_stopping=True, categorical_features=final_mask, random_state=0)\n",
    "print(\"Begin CV\")\n",
    "for train_index , test_index in kfold.split(X_new, y_new):\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    cv_set_score = clf.score(X_test, y_test)\n",
    "    print(cv_set_score)\n",
    "    arr.append(cv_set_score)\n",
    "print(\"CV mean score: \", np.mean(arr))\n",
    "clf.fit(X_new, y_new)\n",
    "train_score = clf.score(X_new, y_new)\n",
    "print(\"Train set score: \", train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"model.pkl\", 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Grid\n",
    "params = {'max_leaf_nodes':np.arange(10,90, 10), 'l2_regularization':np.arange(0.05,0.4,0.01), 'learning_rate':np.arange(0.01,0.1,0.01), 'max_depth':np.arange(6, 12, 1), 'max_bins':np.arange(16, 34, 2)}\n",
    "#params = {'max_iter':np.arange(50,200,100),'max_leaf_nodes':np.arange(100,500, 10), 'l2_regularization':np.arange(0,1,0.05)}\n",
    "search = GridSearchCV(estimator=HistGradientBoostingClassifier(max_iter=3000, categorical_features=final_mask, early_stopping=True), \n",
    "                                param_grid=params, n_jobs=-1).fit(X_new,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.score(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"hyperparam_search.pkl\", 'wb') as file:\n",
    "    pickle.dump(search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open(\"hyperparam_search.pkl\", 'rb') as file:\n",
    "    search = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGTWpkXcZ7MH"
   },
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "dfX_test = pd.read_table('final-noclass.txt', sep=\"\\s+\", usecols=all, names = list(attr['attr'])[:-1])\n",
    "dfX_test.eval('YEAR = YEAR - 2000', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['B1',\n 'B2',\n 'C1',\n 'C2',\n 'C3',\n 'C4',\n 'C6',\n 'C7',\n 'C8',\n 'C10',\n 'C11',\n 'C15',\n 'C23',\n 'C26',\n 'C28',\n 'C31',\n 'C41',\n 'C46',\n 'C56',\n 'C71',\n 'C76',\n 'C86',\n 'C101',\n 'C116',\n 'C131',\n 'C136',\n 'C137',\n 'C138',\n 'C139',\n 'YEAR',\n 'C140',\n 'C141',\n 'C142',\n 'CT1',\n 'CT2',\n 'CT3',\n 'CT4',\n 'CT5',\n 'CT6',\n 'CT9',\n 'CT10',\n 'CT11',\n 'CT12',\n 'CT13',\n 'CT14',\n 'CT15',\n 'CT16',\n 'CT17',\n 'CT18',\n 'CT19',\n 'CT20',\n 'CT21',\n 'CT22',\n 'CT23',\n 'CT24',\n 'CT25',\n 'CT26']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"histgrad.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file)\n",
    "list(attr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dfX_test[attr_lst].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model then predict and save prediction\n",
    "with open(\"model.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "np.savetxt(fname=\"final.txt\", X=model.predict(X_test), fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
