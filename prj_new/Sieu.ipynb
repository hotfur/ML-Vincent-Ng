{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-NJ2QoENDES"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "nedc4PEzMxZs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "os.chdir(\"/home/sieu/PycharmProjects/ML-Vincent-Ng/prj_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqb0XC5HOl5q"
   },
   "source": [
    "# Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqbBwV2BkPtY"
   },
   "outputs": [],
   "source": [
    "column_name = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "df = pd.read_table('train.txt', sep=\"\\s+\", usecols=all, names = list(column_name['attr']))\n",
    "# Add validation set\n",
    "dfX_pred = pd.read_table('prelim.txt', sep=\"\\s+\", usecols=all, names = list(column_name['attr']))\n",
    "df = pd.concat((df,dfX_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust year\n",
    "df.eval('YEAR = YEAR - 2000', inplace=True)\n",
    "dfX_pred.eval('YEAR = YEAR - 2000', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build histogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.hist(figsize=(90, 90))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate class from attributes\n",
    "y = df[\"Class\"].to_numpy()\n",
    "X = df[df.columns[:-1]]\n",
    "attr_lst = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove all constant-valued features\n",
    "sel = VarianceThreshold()\n",
    "sel.feature_names_in_= attr_lst\n",
    "X=sel.fit_transform(X)\n",
    "attr_lst=sel.get_feature_names_out(attr_lst)\n",
    "print(attr_lst)\n",
    "print(\"Number of features: \", len(attr_lst))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select good features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_fet_to_sel = len(attr_lst)//3\n",
    "\n",
    "print(\"BEGIN: HistGrad classifier feature selection\")\n",
    "berNB = SequentialFeatureSelector(estimator=HistGradientBoostingClassifier(max_leaf_nodes=60,max_iter=3000,learning_rate=0.06,l2_regularization=0.15, max_depth=8, max_bins=24, early_stopping=True, random_state=0),n_features_to_select=n_fet_to_sel, direction=\"forward\").fit(X, y)\n",
    "berNB.feature_names_in_= attr_lst\n",
    "attr_lst = berNB.get_feature_names_out(attr_lst)\n",
    "print(attr_lst)\n",
    "print(\"Done HistGrad classifier feature selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection results\n",
    "with open(\"histgrad.pkl\", 'wb') as file:\n",
    "    pickle.dump(attr_lst, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load good feature list\n",
    "with open(\"histgrad.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file).astype(str)\n",
    "print(attr_lst)\n",
    "print(len(attr_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from clipboard (either load from file or load from clipboard)\n",
    "# attr_lst = ['B1', 'B3', 'C1', 'C2', 'C3', 'C4', 'C6', 'C7', 'C8', 'C12', 'C14',\n",
    "#        'C23', 'C32', 'C39', 'C40', 'C41', 'C45', 'C46', 'C51', 'C54',\n",
    "#        'C77', 'C91', 'C92', 'C99', 'C101', 'C104', 'C105', 'C111', 'C116',\n",
    "#        'C137', 'C141', 'CT18', 'CT19', 'CT22']\n",
    "# attr_lst=np.array(attr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_C_mask = and(C, not(CT or CH))\n",
    "all_C_mask = np.logical_and((np.core.defchararray.find(attr_lst,\"C\")!=-1), np.logical_not(np.logical_or((np.core.defchararray.find(attr_lst,\"CT\")!=-1),(np.core.defchararray.find(attr_lst,\"CH\")!=-1))))\n",
    "# non_C_mask = not(all_C_mask)\n",
    "non_C_mask = np.logical_not(all_C_mask)\n",
    "# final_mask = and(non_C_mask, not(CH_mask))\n",
    "final_mask = np.logical_and(non_C_mask, np.logical_not((np.core.defchararray.find(attr_lst,\"CH\")!=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=df[attr_lst].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = dfX_pred[attr_lst].to_numpy()\n",
    "y_pred = dfX_pred[\"Class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage = 1 #5\n",
    "threshold = (15,35) #(2,12)\n",
    "rng = np.random.default_rng(12345)\n",
    "kfold = sklearn.model_selection.StratifiedKFold(n_splits=100, shuffle=True)\n",
    "y_new = y\n",
    "i=0\n",
    "\n",
    "for train_index , test_index in kfold.split(X_new, y_new):\n",
    "    if i > threshold[1]:\n",
    "        i+=1\n",
    "        continue\n",
    "    if i < threshold[0]:\n",
    "        i+=1\n",
    "        continue\n",
    "    X_new_aug, y_new_aug = X_new[test_index], y_new[test_index]\n",
    "    aug_mask = rng.choice(a=[0,1], size=X_new_aug.shape, p=[1-(damage*i)/100, (damage*i)/100])\n",
    "    X_new_aug[aug_mask] = np.nan\n",
    "    X_new = np.concatenate((X_new, X_new_aug), axis=0)\n",
    "    y_new = np.concatenate((y_new, y_new_aug))\n",
    "    i+=1\n",
    "print((X_new.shape, y_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best model validation\n",
    "kfold = sklearn.model_selection.StratifiedKFold(n_splits=5, shuffle=True)\n",
    "arr = []\n",
    "#clf = BernoulliNB()\n",
    "clf = HistGradientBoostingClassifier(max_leaf_nodes=60,max_iter=3000,learning_rate=0.06,l2_regularization=0.15, max_depth=8, max_bins=24, early_stopping=True, categorical_features=final_mask, random_state=0)\n",
    "# clf.fit(X_new, y_new)\n",
    "# val_set_score = clf.score(X_pred, y_pred)\n",
    "# print(val_set_score)\n",
    "for train_index , test_index in kfold.split(X_new, y_new):\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y_new[train_index], y_new[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    cv_set_score = clf.score(X_test, y_test)\n",
    "    print(cv_set_score)\n",
    "    arr.append(cv_set_score)\n",
    "print(\"Done\")\n",
    "#print(\"mean acc: \", np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"model.pkl\", 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Grid\n",
    "params = {'max_leaf_nodes':np.arange(10,90, 10), 'l2_regularization':np.arange(0.05,0.4,0.01), 'learning_rate':np.arange(0.01,0.1,0.01), 'max_depth':np.arange(6, 12, 1), 'max_bins':np.arange(16, 34, 2)}\n",
    "#params = {'max_iter':np.arange(50,200,100),'max_leaf_nodes':np.arange(100,500, 10), 'l2_regularization':np.arange(0,1,0.05)}\n",
    "search = GridSearchCV(estimator=HistGradientBoostingClassifier(max_iter=3000, categorical_features=final_mask, early_stopping=True), \n",
    "                                param_grid=params, n_jobs=-1).fit(X_new,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.score(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"hyperparam_search.pkl\", 'wb') as file:\n",
    "    pickle.dump(search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open(\"hyperparam_search.pkl\", 'rb') as file:\n",
    "    search = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGTWpkXcZ7MH"
   },
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "dfX_test = pd.read_table('prelim.txt', sep=\"\\s+\", usecols=all, names = list(attr['attr'])[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"histgrad.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file)\n",
    "list(attr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dfX_test[attr_lst].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model then predict and save prediction\n",
    "with open(\"77_alldataset.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "np.savetxt(fname=\"prediction.txt\", X=model.predict(X_test), fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
