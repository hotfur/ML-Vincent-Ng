{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-NJ2QoENDES"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nedc4PEzMxZs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, sys\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "os.chdir(\"/home/sieu/PycharmProjects/ML-Vincent-Ng/project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqb0XC5HOl5q"
   },
   "source": [
    "# Training import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MqbBwV2BkPtY"
   },
   "outputs": [],
   "source": [
    "column_name = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "df = pd.read_table('train.txt', sep=\"\\s+\", usecols=all, names = list(column_name['attr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQmTIelVmexu",
    "outputId": "f747088a-64d9-4766-bb0a-9e96f84a4221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>...</th>\n",
       "      <th>CT22</th>\n",
       "      <th>CT23</th>\n",
       "      <th>CT24</th>\n",
       "      <th>CT25</th>\n",
       "      <th>CT26</th>\n",
       "      <th>CH1</th>\n",
       "      <th>CH2</th>\n",
       "      <th>CH3</th>\n",
       "      <th>CH4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.260</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.720</td>\n",
       "      <td>4.590</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.540</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.720</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.810</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.630</td>\n",
       "      <td>1.215</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.540</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.085</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.945</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.170</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.810</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11982 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       B1  B2  B3     C1    C2     C3     C4    C5     C6     C7  ...  CT22  \\\n",
       "0       0   0   1  1.260  1.17  0.720  4.590  0.45  0.765  0.540  ...     3   \n",
       "1       0   1   0  0.450  0.81  0.000  0.000  0.00  0.855  0.000  ...     3   \n",
       "2       0   0   1  0.540  2.88  0.000  0.000  0.00  0.765  0.000  ...     3   \n",
       "3       0   0   1  0.810  1.35  0.450  0.000  0.00  0.000  0.720  ...     3   \n",
       "4       0   0   1  0.900  1.17  0.765  0.000  0.00  0.630  0.810  ...     4   \n",
       "...    ..  ..  ..    ...   ...    ...    ...   ...    ...    ...  ...   ...   \n",
       "11995   0   1   0  0.450  1.17  0.630  1.215  0.45  0.990  0.540  ...     3   \n",
       "11996   0   1   0  5.085  0.90  0.000  0.000  0.00  0.000  0.945  ...     4   \n",
       "11997   0   0   1  1.170  1.71  0.630  0.000  0.00  0.720  0.000  ...     3   \n",
       "11998   0   0   1  0.810  1.17  0.000  0.000  0.00  0.990  0.810  ...     5   \n",
       "11999   0   0   1  0.000  0.90  0.720  0.000  0.00  0.000  0.000  ...     5   \n",
       "\n",
       "       CT23  CT24  CT25  CT26  CH1  CH2  CH3  CH4  Class  \n",
       "0         2     2     1     3    0    0    0    0      1  \n",
       "1         2     1     1     3    0    0    0    0      1  \n",
       "2         2     2     1     3    0    0    0    0      1  \n",
       "3         2     2     1     3    0    0    0    0      1  \n",
       "4         3     2     1     3    0    0    0    0      1  \n",
       "...     ...   ...   ...   ...  ...  ...  ...  ...    ...  \n",
       "11995     2     2     1     3    0    0    0    0      0  \n",
       "11996     3     2     1     3    0    0    0    0      1  \n",
       "11997     2     1     1     3    0    0    0    0      0  \n",
       "11998     3     2     2     4    0    0    0    0      1  \n",
       "11999     3     2     1     3    0    0    0    0      0  \n",
       "\n",
       "[11982 rows x 176 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "# Save year\n",
    "X_year =  df.loc[:,'YEAR']\n",
    "df.drop(['YEAR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y2TvwGLmvS_e"
   },
   "outputs": [],
   "source": [
    "# Seperate data by type\n",
    "y = df[\"Class\"].to_numpy()\n",
    "X_B = df.loc[:, 'B1':'B3']\n",
    "X_C = df.loc[:,'C1':'C139']\n",
    "X_CT = df.loc[:,'CT1':'CT26']\n",
    "X_H = df.loc[:,'CH1':'CH4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "print(X_B.describe())\n",
    "print(X_C.describe())\n",
    "print(X_CT.describe())\n",
    "print(X_H.describe())\n",
    "print(X_year.describe())\n",
    "print(np.unique(df[[\"CT22\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select good features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the columns retained by each\n",
    "# List contains all attributes retained during feature selection: attr_lst\n",
    "x_c_cols = X_C.columns\n",
    "x_ct_cols = X_CT.columns\n",
    "x_h_cols = X_H.columns\n",
    "# Feature selection based on variance threshold for every type of data\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "# X_C dataframe\n",
    "sel.feature_names_in_= x_c_cols\n",
    "X_C = sel.fit_transform(X_C)\n",
    "x_c_cols=sel.get_feature_names_out(x_c_cols)\n",
    "attr_lst=x_c_cols\n",
    "print(x_c_cols)\n",
    "print(\"Number of C* features: \", len(x_c_cols))\n",
    "\n",
    "# X_CT dataframe\n",
    "sel.feature_names_in_= x_ct_cols\n",
    "X_CT = sel.fit_transform(X_CT)\n",
    "x_ct_cols=sel.get_feature_names_out(x_ct_cols)\n",
    "attr_lst=np.concatenate((attr_lst, x_ct_cols))\n",
    "print(x_ct_cols)\n",
    "print(\"Number of CT* features: \", len(x_ct_cols))\n",
    "\n",
    "# X_H dataframe\n",
    "sel.feature_names_in_= x_h_cols\n",
    "X_H = sel.fit_transform(X_H)\n",
    "x_h_cols=sel.get_feature_names_out(x_h_cols)\n",
    "attr_lst=np.concatenate((attr_lst, x_h_cols))\n",
    "print(x_h_cols)\n",
    "print(\"Number of CH* features: \", len(x_h_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selection_factor = 5\n",
    "attr_lst = []\n",
    "\n",
    "if len(x_c_cols) > 0:    \n",
    "    print(\"BEGIN: Ridge classifier feature selection for C* atttributes\")\n",
    "    sel_X_C = SequentialFeatureSelector(estimator=RidgeClassifierCV(), n_features_to_select=max(len(x_c_cols)//(selection_factor), 1), direction=\"forward\")\n",
    "    sel_X_C.feature_names_in_= x_c_cols\n",
    "    X_C = sel_X_C.fit_transform(X_C, y)\n",
    "    x_c_cols = sel_X_C.get_feature_names_out(x_c_cols)\n",
    "    attr_lst=np.concatenate((attr_lst, x_c_cols))\n",
    "    print(x_c_cols)\n",
    "    print(\"Done Ridge classifier feature selection for C* atttributes\")\n",
    "\n",
    "if len(x_ct_cols) > 0:\n",
    "    print(\"BEGIN: CategoricalNB classifier feature selection for CT* atttributes\")\n",
    "    sel_X_CT = SequentialFeatureSelector(estimator=CategoricalNB(), n_features_to_select=max(len(x_ct_cols)//selection_factor, 1), direction=\"forward\")\n",
    "    sel_X_CT.feature_names_in_= x_ct_cols\n",
    "    X_CT = sel_X_CT.fit_transform(X_CT, y)\n",
    "    x_ct_cols = sel_X_CT.get_feature_names_out(x_ct_cols)\n",
    "    attr_lst=np.concatenate((attr_lst, x_ct_cols))\n",
    "    print(x_ct_cols)\n",
    "    print(\"Done CategoricalNB classifier feature selection for CT* atttributes\")\n",
    "\n",
    "if len(x_h_cols) > 0:\n",
    "    print(\"BEGIN: DecisionTreeClassifier feature selection for CH* atttributes\")\n",
    "    sel_X_H= SequentialFeatureSelector(estimator=DecisionTreeClassifier(), n_features_to_select=max(len(x_h_cols)//selection_factor, 1), direction=\"forward\")\n",
    "    sel_X_H.feature_names_in_= x_h_cols\n",
    "    X_H = sel_X_H.fit_transform(X_H, y)\n",
    "    x_h_cols = sel_X_H.get_feature_names_out(x_h_cols)\n",
    "    attr_lst=np.concatenate((attr_lst, x_h_cols))\n",
    "    print(x_h_cols)\n",
    "    print(\"Done DecisionTreeClassifier feature selection for CH* atttributes\")\n",
    "\n",
    "X=np.concatenate((X_C, X_CT, X_H), axis=1)\n",
    "print(attr_lst)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection results\n",
    "with open(\"_fet.pkl\", 'wb') as file:\n",
    "    pickle.dump(attr_lst, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load good feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1' 'C3' 'C5' 'C6' 'C8' 'C13' 'C16' 'C17' 'C19' 'C26' 'C31' 'C48' 'C53'\n",
      " 'C59' 'C64' 'C69' 'C70' 'C94' 'C97' 'CT3' 'CT16' 'CT26' 'CH3']\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# Load good feature list\n",
    "with open(\"25_fet.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file)\n",
    "print(attr_lst)\n",
    "print(len(attr_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from clipboard\n",
    "attr_lst = ['C1', 'C3', 'C5', 'C6', 'C8', 'C13', 'C16', 'C17', 'C19', 'C26', 'C31', 'C48', 'C53', 'C59', 'C64', 'C69', 'C70', 'C94', 'C97', 'CT3', 'CT16', 'CT26', 'CH3']\n",
    "attr_lst=np.array(attr_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1' 'C3' 'C5' 'C6' 'C8' 'C13' 'C16' 'C17' 'C19' 'C26' 'C31' 'C48' 'C53'\n",
      " 'C59' 'C64' 'C69' 'C70' 'C94' 'C97' 'CT3' 'CT16' 'CT26' 'CH3']\n"
     ]
    }
   ],
   "source": [
    "attr_lst=attr_lst.astype(str)\n",
    "print(attr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11982, 25)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive PCA\n",
    "X = df[attr_lst].to_numpy()\n",
    "pca = PCA(svd_solver='full', n_components='mle')\n",
    "X = pca.fit_transform(X)\n",
    "X_new=np.concatenate((X_B, X), axis=1)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1' 'C3' 'C5' 'C6' 'C8' 'C13' 'C16' 'C17' 'C19' 'C26' 'C31' 'C48' 'C53'\n",
      " 'C59' 'C64' 'C69' 'C70' 'C94' 'C97']\n",
      "Perform PCA on continuous features to filter noises\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# Reseperate C data to perform PCA\n",
    "non_C_ind = np.logical_or((np.core.defchararray.find(attr_lst,\"CT\")!=-1),(np.core.defchararray.find(attr_lst,\"CH\")!=-1))\n",
    "C_label = attr_lst[np.logical_not(non_C_ind)]\n",
    "attr_lst = attr_lst[non_C_ind]\n",
    "print(C_label)\n",
    "X = df[C_label].to_numpy()\n",
    "print('Perform PCA on continuous features to filter noises')\n",
    "pca = PCA(svd_solver='full', n_components='mle')\n",
    "X = pca.fit_transform(X)\n",
    "no_component = len(pca.get_feature_names_out())\n",
    "print(no_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11982, 25)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat X_B with X to get the final attribute array\n",
    "X_new=np.concatenate((X_B, df[attr_lst], X), axis=1)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive PCA\n",
    "params = {'max_leaf_nodes':np.arange(200,500, 20), 'l2_regularization':np.arange(0.5,1,0.05), 'learning_rate':np.arange(0.3,1,0.05), 'max_depth':np.arange(8, 40, 2), 'max_bins':np.arange(70, 150, 2)}\n",
    "#params = {'max_iter':np.arange(50,200,100),'max_leaf_nodes':np.arange(100,500, 10), 'l2_regularization':np.arange(0,1,0.05)}\n",
    "search = HalvingRandomSearchCV(estimator=HistGradientBoostingClassifier(categorical_features=[0, 1, 2]), \n",
    "                                param_distributions=params, factor=2).fit(X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaf_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m340\u001b[39m, \u001b[38;5;241m20\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_regularization\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.05\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.3\u001b[39m,\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m0.05\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_bins\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m2\u001b[39m)}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#params = {'max_iter':np.arange(50,200,100),'max_leaf_nodes':np.arange(100,500, 10), 'l2_regularization':np.arange(0,1,0.05)}\u001b[39;00m\n\u001b[1;32m      4\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mHalvingRandomSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHistGradientBoostingClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mno_component\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m----> 5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:261\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    254\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    255\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    256\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    257\u001b[0m )\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples_orig \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_index_]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:366\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    359\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    361\u001b[0m more_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [itr] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: [n_resources] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    364\u001b[0m }\n\u001b[0;32m--> 366\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmore_results\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m n_candidates_to_keep \u001b[38;5;241m=\u001b[39m ceil(n_candidates \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor)\n\u001b[1;32m    371\u001b[0m candidate_params \u001b[38;5;241m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:396\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    394\u001b[0m X_binned_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_data(X_train, is_training_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     X_binned_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     X_binned_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:867\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._bin_data\u001b[0;34m(self, X, is_training_data)\u001b[0m\n\u001b[1;32m    865\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_mapper\u001b[38;5;241m.\u001b[39mfit_transform(X)  \u001b[38;5;66;03m# F-aligned array\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_mapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# F-aligned array\u001b[39;00m\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;66;03m# We convert the array to C-contiguous since predicting is faster\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# with this layout (training is faster on F-arrays though)\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     X_binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(X_binned)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/AIC21_MTMC/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/binning.py:277\u001b[0m, in \u001b[0;36m_BinMapper.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    275\u001b[0m n_threads \u001b[38;5;241m=\u001b[39m _openmp_effective_n_threads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_threads)\n\u001b[1;32m    276\u001b[0m binned \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(X, dtype\u001b[38;5;241m=\u001b[39mX_BINNED_DTYPE, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m \u001b[43m_map_to_bins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbin_thresholds_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing_values_bin_idx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinned\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binned\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normal Grid\n",
    "params = {'max_leaf_nodes':np.arange(200,340, 20), 'l2_regularization':np.arange(0.5,1,0.05), 'learning_rate':np.arange(0.3,1.0,0.05), 'max_depth':np.arange(15, 30, 2), 'max_bins':np.arange(70, 120, 2)}\n",
    "#params = {'max_iter':np.arange(50,200,100),'max_leaf_nodes':np.arange(100,500, 10), 'l2_regularization':np.arange(0,1,0.05)}\n",
    "search = HalvingRandomSearchCV(estimator=HistGradientBoostingClassifier(max_iter=300, categorical_features=np.arange(0,X_new.shape[1]-no_component), early_stopping=True), \n",
    "                                param_distributions=params, factor=2).fit(X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982485404503753\n",
      "0.8840700583819849\n",
      "0.8898163606010017\n",
      "0.9048414023372288\n",
      "0.8973288814691152\n",
      "0.8898163606010017\n",
      "0.9106844741235393\n",
      "0.9098497495826378\n",
      "0.9090150250417363\n",
      "0.9031719532554258\n",
      "Done\n",
      "mean acc:  0.8996842805844046\n"
     ]
    }
   ],
   "source": [
    "# Best model validation\n",
    "kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
    "arr = []\n",
    "for train_index , test_index in kfold.split(X):\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #clf = HistGradientBoostingClassifier(categorical_features=[0, 1, 2, 4,5,6], max_leaf_nodes=300,max_iter=300,learning_rate=0.5,l2_regularization=0.95).fit(X_train, y_train)\n",
    "    #print(clf.score(X_test, y_test))\n",
    "    #arr.append(clf.score(X_test, y_test))\n",
    "    arr.append(search.score(X_test, y_test))\n",
    "    print(search.score(X_test, y_test))\n",
    "print(\"Done\")\n",
    "print(\"mean acc: \", np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(\"927_newmethod.pkl\", 'wb') as file:\n",
    "    pickle.dump(search, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open(\"888_low_depth_leaf_model_newmethod.pkl\", 'rb') as file:\n",
    "    search = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 200,\n",
       " 'max_depth': 36,\n",
       " 'max_bins': 118,\n",
       " 'learning_rate': 0.3,\n",
       " 'l2_regularization': 0.55}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_classifiers(data):\n",
    "    clf = RidgeClassifier(solver=\"svd\")\n",
    "    clf.fit(data[0], data[1])\n",
    "    score = clf.score(data[2], data[3])\n",
    "    return (clf, score)\n",
    "def knn_classifiers(data):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    clf.fit(data[0], data[1])\n",
    "    score = clf.score(data[2], data[3])\n",
    "    return (clf, score)\n",
    "def svc_classifiers(data):\n",
    "    clf = SVC(kernel='rbf', degree=3)\n",
    "    clf.fit(data[0], data[1])\n",
    "    score = clf.score(data[2], data[3])\n",
    "    return (clf, score)\n",
    "def BernoulliNB_classifiers(data):\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(data[0], data[1])\n",
    "    score = clf.score(data[2], data[3])\n",
    "    return (clf, score)\n",
    "def HGB_classifiers(data):\n",
    "    clf = HistGradientBoostingClassifier(categorical_features=[0, 1, 2])\n",
    "    clf.fit(data[0], data[1])\n",
    "    score = clf.score(data[2], data[3])\n",
    "    return (clf, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
    "dataset = []\n",
    "for train_index , test_index in kfold.split(X):\n",
    "    X_train, X_test = X_new[train_index], X_new[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    dataset.append((X_train, y_train, X_test, y_test))\n",
    "    #Testing individual clf\n",
    "    clf = HistGradientBoostingClassifier(categorical_features=[0, 1, 2], max_leaf_nodes=800,max_iter=300,learning_rate=0.8500000000000002,l2_regularization=0.8500000000000001).fit(X_train, y_train)\n",
    "    #assembly.append(clf)\n",
    "    #vote_weights.append(clf.score(X_test, y_test))\n",
    "    #clf = RidgeClassifier(solver=\"svd\").fit(X_train, y_train)\n",
    "    #assembly.append(clf)\n",
    "    #vote_weights.append(clf.score(X_test, y_test))\n",
    "    #clf = BernoulliNB().fit(X_train, y_train)\n",
    "    #assembly.append(clf)\n",
    "    #vote_weights.append(clf.score(X_test, y_test))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly = []\n",
    "vote_weights = []\n",
    "def append_results(result):\n",
    "    for clf, score in result:\n",
    "        assembly.append(clf)\n",
    "        vote_weights.append(score)\n",
    "if __name__ == '__main__':\n",
    "    p = Pool()\n",
    "    p.map_async(Ridge_classifiers, dataset, callback=append_results)\n",
    "    #p.map_async(nn_classifiers, dataset, callback=append_results)\n",
    "    #p.map_async(knn_classifiers, dataset, callback=append_results)\n",
    "    #p.map_async(svc_classifiers, dataset, callback=append_results)\n",
    "    p.map_async(BernoulliNB_classifiers, dataset, callback=append_results)\n",
    "    p.map_async(HGB_classifiers, dataset, callback=append_results)\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assembly)\n",
    "print(vote_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "for i in range(len(assembly)):\n",
    "    clfs.append((\"Classifier \" + str(i), assembly[i]))\n",
    "eclf = VotingClassifier(estimators=clfs,voting='hard', weights=vote_weights, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(eclf, X_new, y, scoring='accuracy', cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGTWpkXcZ7MH"
   },
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "dfX_pred = pd.read_table('sample-test.txt', sep=\"\\s+\", usecols=all, names = list(attr['attr'])[:-1])\n",
    "dfX_pred = dfX_pred.dropna()\n",
    "dfX_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate prediction data by type\n",
    "X_pred_B = dfX_pred.loc[:, 'B1':'B3']\n",
    "X_pred_C = dfX_pred.loc[:,'C1':'C139']\n",
    "X_pred_CT = dfX_pred.loc[:,'CT1':'CT26']\n",
    "X_pred_H = dfX_pred.loc[:,'CH1':'CH4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feat_sel_result.pkl\", 'rb') as file:\n",
    "    attr_lst = pickle.load(file)\n",
    "list(attr_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List contains all attributes retained during feature selection: attr_lst\n",
    "# Feature selection based on variance threshold for every type of data\n",
    "\n",
    "X_pred=pd.concat((X_pred_C, X_pred_CT, X_pred_H), axis=1)\n",
    "X_pred=X_pred.loc[:,list(attr_lst)]\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perform PCA on remaining feature to filter noises')\n",
    "pca = PCA(svd_solver='full', n_components=len(principal_comp))\n",
    "X_pred = pca.fit_transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat X_B with X to get the final attribute array\n",
    "X_pred_new=np.concatenate((X_pred_B,X_pred), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model then predict and save prediction\n",
    "with open(\"91_model.pkl\", 'rb') as file:\n",
    "    search = pickle.load(file)\n",
    "y_pred = search.predict(X_pred_new)\n",
    "np.savetxt(fname=\"prediction.txt\", X=y_pred, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
