{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import lib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "(11982, 177)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr = pd.read_table('attr.txt', sep=\":\", usecols=all, names = ['attr', 'range'])\n",
    "train = pd.read_table('train.txt', sep=\"\\s+\", usecols=all, names = list(attr['attr']))\n",
    "\n",
    "#clean data:\n",
    "train = train.drop_duplicates()\n",
    "train = train.dropna()\n",
    "\n",
    "#get test set\n",
    "X_va = pd.read_table('sample-test.txt', sep=\"\\s+\", usecols=all, names = list(attr['attr'])[:-1])\n",
    "y_va = pd.read_table('predicted.txt', usecols=all,  names = ['Class'])\n",
    "train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "class FeatureSelection:\n",
    "    def __init__(self, x_in, y_in):\n",
    "        self.x = x_in\n",
    "        self.y = y_in\n",
    "\n",
    "    def model(self, model_name):\n",
    "        # Choose model\n",
    "        match model_name:\n",
    "            case 'extra_tree':\n",
    "                return FeatureSelection.extra_tree(self)\n",
    "            case 'univariate':\n",
    "                return FeatureSelection.univariate(self)\n",
    "            case 'rand_forest':\n",
    "                return FeatureSelection.rand_forest(self)\n",
    "\n",
    "    def extra_tree(self):\n",
    "        # Tree-based feature selection\n",
    "        clf = ExtraTreesClassifier(n_estimators=100, criterion='entropy', random_state=42, max_depth=9)\n",
    "        clf = clf.fit(self.x, self.y)\n",
    "        ext_model = SelectFromModel(clf, prefit=True)\n",
    "        x_new = ext_model.transform(self.x)\n",
    "        print('ExtraTree feature:', x_new.shape)\n",
    "        return x_new\n",
    "\n",
    "    def univariate(self):\n",
    "        # Univariate feature selection\n",
    "        x_new = SelectKBest(chi2, k=5).fit_transform(self.x, self.y)\n",
    "        print('Univariate feature:', x_new.shape)\n",
    "        return x_new\n",
    "\n",
    "    def rand_forest(self):\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=9, random_state=42)\n",
    "        clf.fit(self.x, self.y)\n",
    "        ext_model = SelectFromModel(clf, prefit=True)\n",
    "        x_new = ext_model.transform(self.x)\n",
    "        print('ExtraTree feature:', x_new.shape)\n",
    "        return x_new\n",
    "\n",
    "    def dis_feature(self):\n",
    "\n",
    "        return\n",
    "\n",
    "    def linear_feature(self):\n",
    "        return\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "class SplitModel:\n",
    "    def __init__(self, x_in, y_in):\n",
    "        self.x = x_in\n",
    "        self.y = y_in\n",
    "\n",
    "    def model(self, model_name):\n",
    "        # Choose model\n",
    "        match model_name:\n",
    "            case 'rand_split':\n",
    "                return SplitModel.rand_split(self)\n",
    "            case 'distribution_plit':\n",
    "                return SplitModel.distribution_split(self)\n",
    "\n",
    "\n",
    "    def rand_split(self):\n",
    "        return train_test_split(self.x, self.y , test_size=0.2, random_state = 42)\n",
    "\n",
    "    def distribution_split(self):\n",
    "        return\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "class TrainingModel:\n",
    "    def __init__(self, x_tr, x_te, y_tr, y_te):\n",
    "        self.x_tr = x_tr\n",
    "        self.x_te = x_te\n",
    "        self.y_tr = y_tr\n",
    "        self.y_te = y_te\n",
    "\n",
    "    def model(self, model_name):\n",
    "        # Choose model\n",
    "        match model_name:\n",
    "            case 'gaussianNB':\n",
    "                return TrainingModel.gaussian_NB(self)\n",
    "            case 'SVM':\n",
    "                return TrainingModel.SVM(self)\n",
    "\n",
    "    def gaussian_NB(self):\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(self.x_tr, self.y_tr)\n",
    "        # Check accuracy score\n",
    "        y_NB_pred = gnb.predict(self.x_te)\n",
    "        return accuracy_score(self.y_te, y_NB_pred)\n",
    "\n",
    "    def SVM(self):\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(self.x_tr, self.y_tr)\n",
    "        y_SVM_pred = clf.predict(self.x_te)\n",
    "        return accuracy_score(self.y_te, y_SVM_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTree feature: (11982, 11)\n",
      "Accuracy: 0.7129745515227367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\python\\venv\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train = train[train.columns[:-1]]\n",
    "y_train = train['Class']\n",
    "\n",
    "# Feature selection\n",
    "feature_model = ['extra_tree', 'univariate', 'rand_forest']\n",
    "fea_se = FeatureSelection(x_train, y_train)\n",
    "x_new = fea_se.model(feature_model[0])\n",
    "\n",
    "# Split data\n",
    "split_way = ['rand_split', 'distribution_plit']\n",
    "split = SplitModel(x_new, y_train)\n",
    "X_train, X_test, y_train, y_test = split.model(split_way[0])\n",
    "\n",
    "#Training\n",
    "training_method = ['gaussianNB', 'SVM']\n",
    "training_model = TrainingModel(X_train, X_test, y_train, y_test)\n",
    "print('Accuracy:',training_model.model(training_method[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
