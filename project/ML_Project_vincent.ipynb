{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-NJ2QoENDES"
   },
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nedc4PEzMxZs",
    "outputId": "a7b7294f-cd1d-4b06-d22d-233551d8ec1e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lqb0XC5HOl5q"
   },
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD7YxwrGPGnc"
   },
   "source": [
    "## For google colab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YVLH2q1aQ7uw"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir(\"/home/sieu/PycharmProjects/ML-Vincent-Ng/project\")\n",
    "sys.path.append(\"/home/sieu/PycharmProjects/ML-Vincent-Ng/project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4lGYIJ_S1ko"
   },
   "source": [
    "## File to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuynVYzlgnN3"
   },
   "source": [
    "Add column names into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FbBj7jNgmv8",
    "outputId": "7adebb16-b088-4099-e264-50ad25791a3a"
   },
   "outputs": [],
   "source": [
    "column_name = []\n",
    "# Open the file with relative path\n",
    "with open('./attr.txt', 'r') as infile:\n",
    "    # Read all data lines as a list of strings\n",
    "    data_lines = infile.readlines() \n",
    "\n",
    "    # Extract each data line\n",
    "    for ind, line in enumerate(data_lines):\n",
    "        line_noendl = line[:-1] # remove the last character of string, which is '\\n'\n",
    "        data = line_noendl.split(':') # split the string by tab '\\t' to get a tuple \n",
    "        column_name.append(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eswbqwFAh43L"
   },
   "source": [
    "Import data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MqbBwV2BkPtY"
   },
   "outputs": [],
   "source": [
    "# Should create a new txt file instead for replace ' ' with '\\t'\n",
    "df2 = pd.DataFrame(columns = column_name)\n",
    "# Open the file with relative path\n",
    "with open('./train.txt', 'r') as infile:\n",
    "    # Read all data lines as a list of strings\n",
    "    data_lines = infile.readlines() \n",
    "    with open('./train2.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "      for column in column_name:\n",
    "        outfile.write(column)\n",
    "        outfile.write('\\t')\n",
    "      outfile.write('\\n')\n",
    "      # Extract each data line\n",
    "      for ind, line in enumerate(data_lines):\n",
    "        line_noendl = line[:-1] # remove the last character of string, which is '\\n'\n",
    "        data = line_noendl.split('\\t') # split the string by tab '\\t' to get a tuple \n",
    "        append_list = []\n",
    "        for i in data:\n",
    "          a = i.split(' ') # additional for removing the ' ' in the dataset\n",
    "          for j in a:\n",
    "            if (j!=''):\n",
    "              append_list.append(j)\n",
    "        for idx, value in enumerate(append_list):\n",
    "          outfile.write(value)\n",
    "          if (idx<len(column_name)-1):\n",
    "            outfile.write('\\t')\n",
    "        outfile.write('\\n')\n",
    "df2 = pd.read_table('train2.txt', sep = '\\t')\n",
    "df = df2.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoIfzT-e8DPe"
   },
   "source": [
    "# Clean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TVAoj9DjUx5"
   },
   "source": [
    "# Remove duplicates, Drop NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ZQmTIelVmexu",
    "outputId": "bda0fa5e-3168-4046-902c-90b6e303ef3c"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSPEv9i04e4a"
   },
   "source": [
    "# Split into attributes and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cuzhn0Jp4lH3"
   },
   "outputs": [],
   "source": [
    "X = df[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K0A6vuK440DP"
   },
   "outputs": [],
   "source": [
    "Y = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWv4WXItvVNd"
   },
   "source": [
    "# Train and Test (Validation) set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2TvwGLmvS_e",
    "outputId": "671b0383-a1d9-4467-c14c-f02967781389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8387, 176)\n",
      "(3595, 176)\n",
      "(8387,)\n",
      "(3595,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training - testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state = 250)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NynIfhwuvbAB"
   },
   "outputs": [],
   "source": [
    "kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9mlnxNL4H1w"
   },
   "source": [
    "### Evaluation on Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "RPwtiU67AGLZ",
    "outputId": "105a9df9-f290-4f5a-ea22-67404bf0d18f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 3), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 3), random_state=1,\n",
       "              solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 3), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
    "for train_index , test_index in kfold.split(train_no_label):\n",
    "    X_train, X_test = train_no_label[train_index], train_no_label[test_index]\n",
    "    y_train, y_test = train_label[train_index], train_label[test_index]\n",
    "    dtree = sklearn.tree.DecisionTreeClassifier(criterion='entropy')\n",
    "    dtree.fit(X_train, y_train)\n",
    "    nn = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 3), random_state=1)\n",
    "    nn.fit(X_train, y_train)\n",
    "    prediction = nn.predict(X_test)\n",
    "    print(\"score is: \", sklearn.metrics.accuracy_score(y_test, prediction))\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
